1、LR原理与推导
  1.1 原理推导
  1.2 交叉熵损失函数
  1.3 LR为什么simod函数
    平滑可导；指数族分布与广义线性模型推导；
  1.4 LR要用交叉熵损失而不是平方损失
    如果平方损失，非凸函数； 如果用平方差在求梯度是与sigmod有关，当模型输出接近0或1时，梯度很小，收敛会很慢，出现梯度消失；
  1.5 LR为什么用离散特征
    
  
2、SVM原理
  2.1 原理
  2.2 非线性与核函数
  
3、LR与SVM区别
  LR损失函数交叉熵与SVM合页损失；
  LR参数模型，SVM非参数模型；
  SVM加入了正则化，结构经验风险最小化；
  SVM与支持向量机有关，LR与所有样本有关；
  对于非线性问题处理，SVM使用核函数，LR不采用核函数，采用特征组合；
  
